"""
Gemini MCP í´ë¼ì´ì–¸íŠ¸ - MCP ì„œë²„ì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
"""

import asyncio
import json
import subprocess
import sys
import os
import platform
import threading
import queue
from typing import Dict, Any, List, Optional

# import google.generativeai as genai 2025ë…„ 8ì›” 31ì¼ ì´í›„ ì¢…ë£Œ

from google import genai
from dataclasses import dataclass


async def call_tool(
    self, server_name: str, tool_name: str, arguments: Dict[str, Any]
) -> Optional[str]:
    """
    MCP ì„œë²„ì˜ ë„êµ¬ í˜¸ì¶œ

    Args:
        server_name: ì„œë²„ ì´ë¦„
        tool_name: ë„êµ¬ ì´ë¦„
        arguments: ë„êµ¬ ì¸ìˆ˜

    Returns:
        ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
    """
    if server_name not in self.servers:
        return f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    server = self.servers[server_name]

    try:
        tool_request = {
            "jsonrpc": "2.0",
            "id": 3,
            "method": "tools/call",
            "params": {"name": tool_name, "arguments": arguments},
        }

        server.input_queue.put(json.dumps(tool_request))

        # ì‘ë‹µ ì½ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
        for _ in range(100):  # 10ì´ˆ ëŒ€ê¸°
            try:
                response_line = server.output_queue.get(timeout=0.1)
                if response_line:
                    response = json.loads(response_line)

                    if "result" in response:
                        content = response["result"].get("content", [])
                        if content and len(content) > 0:
                            return content[0].get("text", "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                    elif "error" in response:
                        return f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {response['error']['message']}"

                    return "ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹ì…ë‹ˆë‹¤."
            except queue.Empty:
                continue
            except json.JSONDecodeError as e:
                print(f"ë„êµ¬ ì‘ë‹µ JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}")
                continue

        return "ë„êµ¬ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ"

    except Exception as e:
        return f"ë„êµ¬ í˜¸ì¶œ ì¤‘ ì˜¤#!/usr/bin/env python3"


# Windowsì—ì„œ ProactorEventLoop ë¬¸ì œ í•´ê²°
if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())


@dataclass
class MCPServer:
    """MCP ì„œë²„ ì •ë³´"""

    name: str
    process: subprocess.Popen
    tools: List[Dict[str, Any]]
    input_queue: queue.Queue
    output_queue: queue.Queue
    error_queue: queue.Queue


class GeminiMCPClient:
    def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash-001"):
        """
        Gemini MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

        Args:
            api_key: Gemini API í‚¤
            model_name: ì‚¬ìš©í•  Gemini ëª¨ë¸ëª…
        """
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        self.servers: Dict[str, MCPServer] = {}
        self.chat_session = None

    def _read_output(self, process, output_queue, error_queue):
        """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ ì½ê¸°"""

        def read_stdout():
            try:
                while True:
                    line = process.stdout.readline()
                    if not line:
                        break
                    output_queue.put(line.strip())
            except Exception as e:
                error_queue.put(f"stdout ì½ê¸° ì˜¤ë¥˜: {e}")

        def read_stderr():
            try:
                while True:
                    line = process.stderr.readline()
                    if not line:
                        break
                    error_queue.put(f"stderr: {line.strip()}")
            except Exception as e:
                error_queue.put(f"stderr ì½ê¸° ì˜¤ë¥˜: {e}")

        # stdout, stderr ê°ê° ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì½ê¸°
        stdout_thread = threading.Thread(target=read_stdout, daemon=True)
        stderr_thread = threading.Thread(target=read_stderr, daemon=True)

        stdout_thread.start()
        stderr_thread.start()

    def _write_input(self, process, input_queue):
        """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ í”„ë¡œì„¸ìŠ¤ ì…ë ¥ ì“°ê¸°"""

        def write_stdin():
            try:
                while True:
                    try:
                        message = input_queue.get(timeout=0.1)
                        if message is None:  # ì¢…ë£Œ ì‹ í˜¸
                            break
                        process.stdin.write(message + "\n")
                        process.stdin.flush()
                    except queue.Empty:
                        continue
                    except Exception as e:
                        print(f"stdin ì“°ê¸° ì˜¤ë¥˜: {e}")
                        break
            except Exception as e:
                print(f"ì…ë ¥ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")

        input_thread = threading.Thread(target=write_stdin, daemon=True)
        input_thread.start()
        return input_thread

    async def connect_server(self, server_path: str) -> bool:
        """
        MCP ì„œë²„ì— ì—°ê²°

        Args:
            server_path: MCP ì„œë²„ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ

        Returns:
            ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            # í ìƒì„±
            input_queue = queue.Queue()
            output_queue = queue.Queue()
            error_queue = queue.Queue()

            # ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
            process = subprocess.Popen(
                [sys.executable, server_path],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=0,
            )

            # I/O ìŠ¤ë ˆë“œ ì‹œì‘
            self._read_output(process, output_queue, error_queue)
            input_thread = self._write_input(process, input_queue)

            # ì´ˆê¸°í™” ë©”ì‹œì§€ ì „ì†¡
            init_request = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "initialize",
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {"tools": {}},
                    "clientInfo": {"name": "gemini-mcp-client", "version": "1.0.0"},
                },
            }

            input_queue.put(json.dumps(init_request))

            # ì‘ë‹µ ì½ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
            response_received = False
            response_line = ""
            for _ in range(50):  # 5ì´ˆ ëŒ€ê¸°
                try:
                    response_line = output_queue.get(timeout=0.1)
                    if response_line:
                        response = json.loads(response_line)
                        print(f"ì„œë²„ ì´ˆê¸°í™” ì‘ë‹µ: {response}")
                        response_received = True
                        break
                except queue.Empty:
                    continue
                except json.JSONDecodeError as e:
                    print(f"JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}, ì‘ë‹µ: {response_line}")
                    continue

            if not response_received:
                print("ì´ˆê¸°í™” ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                process.terminate()
                return False

            # ë„êµ¬ ëª©ë¡ ìš”ì²­
            tools_request = {
                "jsonrpc": "2.0",
                "id": 2,
                "method": "tools/list",
                "params": {},
            }

            input_queue.put(json.dumps(tools_request))

            # ë„êµ¬ ëª©ë¡ ì‘ë‹µ ì½ê¸°
            tools_received = False
            for _ in range(50):
                try:
                    tools_response_line = output_queue.get(timeout=0.1)
                    if tools_response_line:
                        tools_response = json.loads(tools_response_line)

                        if "result" in tools_response:
                            tools = tools_response["result"].get("tools", [])
                            server_name = os.path.basename(server_path)

                            self.servers[server_name] = MCPServer(
                                name=server_name,
                                process=process,
                                tools=tools,
                                input_queue=input_queue,
                                output_queue=output_queue,
                                error_queue=error_queue,
                            )

                            print(f"âœ… ì„œë²„ '{server_name}' ì—°ê²° ì„±ê³µ")
                            print(
                                f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[tool['name'] for tool in tools]}"
                            )
                            tools_received = True
                            break
                        else:
                            print(f"ë„êµ¬ ëª©ë¡ ì‘ë‹µ ì˜¤ë¥˜: {tools_response}")
                            break
                except queue.Empty:
                    continue
                except json.JSONDecodeError as e:
                    print(f"ë„êµ¬ ëª©ë¡ JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}")
                    continue

            if not tools_received:
                print(f"âŒ ì„œë²„ '{server_path}' ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
                process.terminate()
                return False

            return True

        except Exception as e:
            print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    async def call_tool(
        self, server_name: str, tool_name: str, arguments: Dict[str, Any]
    ) -> Optional[str]:
        """
        MCP ì„œë²„ì˜ ë„êµ¬ í˜¸ì¶œ

        Args:
            server_name: ì„œë²„ ì´ë¦„
            tool_name: ë„êµ¬ ì´ë¦„
            arguments: ë„êµ¬ ì¸ìˆ˜

        Returns:
            ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
        """
        if server_name not in self.servers:
            return f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        server = self.servers[server_name]

        try:
            tool_request = {
                "jsonrpc": "2.0",
                "id": 3,
                "method": "tools/call",
                "params": {"name": tool_name, "arguments": arguments},
            }

            server.input_queue.put(json.dumps(tool_request))

            # ì‘ë‹µ ì½ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
            for _ in range(100):  # 10ì´ˆ ëŒ€ê¸°
                try:
                    response_line = server.output_queue.get(timeout=0.1)
                    if response_line:
                        response = json.loads(response_line)

                        if "result" in response:
                            content = response["result"].get("content", [])
                            if content and len(content) > 0:
                                return content[0].get("text", "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
                        elif "error" in response:
                            return f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {response['error']['message']}"

                        return "ì•Œ ìˆ˜ ì—†ëŠ” ì‘ë‹µ í˜•ì‹ì…ë‹ˆë‹¤."
                except queue.Empty:
                    continue
                except json.JSONDecodeError as e:
                    print(f"ë„êµ¬ ì‘ë‹µ JSON ë””ì½”ë”© ì˜¤ë¥˜: {e}")
                    continue

            return "ë„êµ¬ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ"

        except Exception as e:
            return f"ë„êµ¬ í˜¸ì¶œ ì¤‘ ì˜¤#!/usr/bin/env python3"

    def get_available_tools(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        all_tools = []
        for server_name, server in self.servers.items():
            for tool in server.tools:
                tool_info = tool.copy()
                tool_info["server"] = server_name
                all_tools.append(tool_info)
        return all_tools

    async def chat(self, message: str) -> str:
        """
        Geminiì™€ ì±„íŒ…í•˜ë©° í•„ìš”ì‹œ MCP ë„êµ¬ ì‚¬ìš©

        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            Gemini ì‘ë‹µ
        """
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        tools_info = self.get_available_tools()
        tools_description = "\n".join(
            [
                f"- {tool['name']} (ì„œë²„: {tool['server']}): {tool['description']}"
                for tool in tools_info
            ]
        )

        system_prompt = f"""
ë‹¹ì‹ ì€ MCP(Model Context Protocol) ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
{tools_description}

ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ë„êµ¬ê°€ í•„ìš”í•˜ë‹¤ë©´, ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë„êµ¬ í˜¸ì¶œì„ ìš”ì²­í•˜ì„¸ìš”:

TOOL_CALL: {{
  "server": "ì„œë²„ëª…",
  "tool": "ë„êµ¬ëª…",
  "arguments": {{ì¸ìˆ˜ ë”•ì…”ë„ˆë¦¬}}
}}

ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ë¥¼ ë°›ì€ í›„ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
"""

        try:
            full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì: {message}"
            response = self.model.generate_content(full_prompt)
            response_text = response.text

            # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œì§€ í™•ì¸
            if "TOOL_CALL:" in response_text:
                # ë„êµ¬ í˜¸ì¶œ ë¶€ë¶„ ì¶”ì¶œ
                tool_call_start = response_text.find("TOOL_CALL:")
                tool_call_end = response_text.find("}", tool_call_start) + 1
                tool_call_json = response_text[
                    tool_call_start + 10 : tool_call_end
                ].strip()

                try:
                    tool_call = json.loads(tool_call_json)
                    server_name = tool_call["server"]
                    tool_name = tool_call["tool"]
                    arguments = tool_call["arguments"]

                    print(f"ğŸ”§ ë„êµ¬ í˜¸ì¶œ: {server_name}/{tool_name}")

                    # ë„êµ¬ ì‹¤í–‰
                    tool_result = await self.call_tool(
                        server_name, tool_name, arguments
                    )

                    # ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•œ ìµœì¢… ì‘ë‹µ ìƒì„±
                    final_prompt = f"""
{system_prompt}

ì‚¬ìš©ì: {message}

ë„êµ¬ í˜¸ì¶œ ê²°ê³¼:
ì„œë²„: {server_name}
ë„êµ¬: {tool_name}
ê²°ê³¼: {tool_result}

ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
"""

                    final_response = self.model.generate_content(final_prompt)
                    return final_response.text

                except json.JSONDecodeError:
                    return response_text

            return response_text

        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def cleanup(self):
        """ëª¨ë“  ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬"""
        for server in self.servers.values():
            server.process.terminate()
        self.servers.clear()


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    client = GeminiMCPClient(api_key)

    # ëª…ë ¹ì¤„ ì¸ìˆ˜ë¡œ ì „ë‹¬ëœ ì„œë²„ë“¤ ì—°ê²°
    if len(sys.argv) > 1:
        for server_path in sys.argv[1:]:
            await client.connect_server(server_path)

    print("\nğŸ¤– Gemini MCP ì±„íŒ… ì‹œì‘")
    print("ëª…ë ¹ì–´:")
    print("- 'add_server <ê²½ë¡œ>': ìƒˆ MCP ì„œë²„ ì¶”ê°€")
    print("- 'list_tools': ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡")
    print("- 'quit': ì¢…ë£Œ")
    print("-" * 50)

    try:
        while True:
            user_input = input("\në‹¹ì‹ : ").strip()

            if user_input.lower() == "quit":
                break
            elif user_input.startswith("add_server "):
                server_path = user_input[11:].strip()
                await client.connect_server(server_path)
            elif user_input == "list_tools":
                tools = client.get_available_tools()
                if tools:
                    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:")
                    for tool in tools:
                        print(
                            f"- {tool['name']} ({tool['server']}): {tool['description']}"
                        )
                else:
                    print("ì—°ê²°ëœ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                response = await client.chat(user_input)
                print(f"\nGemini: {response}")

    except KeyboardInterrupt:
        print("\n\nì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

    finally:
        client.cleanup()


if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()
    asyncio.run(main())
